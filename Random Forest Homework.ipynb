{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pandas import read_csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import clone\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n",
    "                              AdaBoostClassifier)\n",
    "from sklearn.externals.six.moves import xrange\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "authorship = read_csv('../../data/authorship.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>at</th>\n",
       "      <th>be</th>\n",
       "      <th>...</th>\n",
       "      <th>what</th>\n",
       "      <th>when</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>would</th>\n",
       "      <th>your</th>\n",
       "      <th>BookID</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td> 24</td>\n",
       "      <td>  8</td>\n",
       "      <td> 1</td>\n",
       "      <td>  5</td>\n",
       "      <td> 54</td>\n",
       "      <td> 1</td>\n",
       "      <td>  3</td>\n",
       "      <td> 11</td>\n",
       "      <td> 12</td>\n",
       "      <td>  7</td>\n",
       "      <td>...</td>\n",
       "      <td> 1</td>\n",
       "      <td> 5</td>\n",
       "      <td>  2</td>\n",
       "      <td> 7</td>\n",
       "      <td>  3</td>\n",
       "      <td>  9</td>\n",
       "      <td>  5</td>\n",
       "      <td>  0</td>\n",
       "      <td> 1</td>\n",
       "      <td> London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td> 40</td>\n",
       "      <td>  6</td>\n",
       "      <td> 0</td>\n",
       "      <td> 17</td>\n",
       "      <td> 53</td>\n",
       "      <td> 1</td>\n",
       "      <td>  3</td>\n",
       "      <td> 10</td>\n",
       "      <td> 17</td>\n",
       "      <td>  6</td>\n",
       "      <td>...</td>\n",
       "      <td> 2</td>\n",
       "      <td> 3</td>\n",
       "      <td>  2</td>\n",
       "      <td> 1</td>\n",
       "      <td>  2</td>\n",
       "      <td> 19</td>\n",
       "      <td>  1</td>\n",
       "      <td>  2</td>\n",
       "      <td> 5</td>\n",
       "      <td> London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td> 29</td>\n",
       "      <td>  4</td>\n",
       "      <td> 1</td>\n",
       "      <td>  2</td>\n",
       "      <td> 61</td>\n",
       "      <td> 0</td>\n",
       "      <td> 14</td>\n",
       "      <td>  8</td>\n",
       "      <td> 13</td>\n",
       "      <td>  6</td>\n",
       "      <td>...</td>\n",
       "      <td> 3</td>\n",
       "      <td> 9</td>\n",
       "      <td>  1</td>\n",
       "      <td> 2</td>\n",
       "      <td>  8</td>\n",
       "      <td> 17</td>\n",
       "      <td>  2</td>\n",
       "      <td> 30</td>\n",
       "      <td> 1</td>\n",
       "      <td> London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td> 41</td>\n",
       "      <td>  9</td>\n",
       "      <td> 1</td>\n",
       "      <td>  4</td>\n",
       "      <td> 42</td>\n",
       "      <td> 7</td>\n",
       "      <td>  3</td>\n",
       "      <td> 14</td>\n",
       "      <td>  6</td>\n",
       "      <td> 18</td>\n",
       "      <td>...</td>\n",
       "      <td> 7</td>\n",
       "      <td> 2</td>\n",
       "      <td> 11</td>\n",
       "      <td> 1</td>\n",
       "      <td>  6</td>\n",
       "      <td> 11</td>\n",
       "      <td> 10</td>\n",
       "      <td>  9</td>\n",
       "      <td> 6</td>\n",
       "      <td> Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td> 25</td>\n",
       "      <td> 10</td>\n",
       "      <td> 2</td>\n",
       "      <td>  4</td>\n",
       "      <td> 45</td>\n",
       "      <td> 1</td>\n",
       "      <td>  4</td>\n",
       "      <td> 14</td>\n",
       "      <td> 10</td>\n",
       "      <td> 13</td>\n",
       "      <td>...</td>\n",
       "      <td> 3</td>\n",
       "      <td> 6</td>\n",
       "      <td>  5</td>\n",
       "      <td> 5</td>\n",
       "      <td> 12</td>\n",
       "      <td>  7</td>\n",
       "      <td>  6</td>\n",
       "      <td>  0</td>\n",
       "      <td> 2</td>\n",
       "      <td> London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a  all  also  an  and  any  are  as  at  be ...  what  when  which  who  \\\n",
       "354  24    8     1   5   54    1    3  11  12   7 ...     1     5      2    7   \n",
       "541  40    6     0  17   53    1    3  10  17   6 ...     2     3      2    1   \n",
       "330  29    4     1   2   61    0   14   8  13   6 ...     3     9      1    2   \n",
       "202  41    9     1   4   42    7    3  14   6  18 ...     7     2     11    1   \n",
       "414  25   10     2   4   45    1    4  14  10  13 ...     3     6      5    5   \n",
       "\n",
       "     will  with  would  your  BookID  Author  \n",
       "354     3     9      5     0       1  London  \n",
       "541     2    19      1     2       5  London  \n",
       "330     8    17      2    30       1  London  \n",
       "202     6    11     10     9       6  Austen  \n",
       "414    12     7      6     0       2  London  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorship.ix[random.sample(authorship.index, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Austen', 'London', 'Shakespeare', 'Milton']\n"
     ]
    }
   ],
   "source": [
    "authors = list(set(authorship.Author.values))\n",
    "print authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace author names with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "...\n",
      "826    3\n",
      "827    3\n",
      "828    3\n",
      "829    3\n",
      "830    3\n",
      "831    3\n",
      "832    3\n",
      "833    3\n",
      "834    3\n",
      "835    3\n",
      "836    3\n",
      "837    3\n",
      "838    3\n",
      "839    3\n",
      "840    3\n",
      "Name: Author_num, Length: 841, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(authors)\n",
    "authorship['Author_num'] = le.transform(authorship['Author'])\n",
    "print authorship['Author_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a random variable (random forests work best with a random variable)\n",
    "authorship['random'] = [random.random() for i in range(841)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'all', 'also', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', 'do', 'down', 'even', 'every', 'for', 'from', 'had', 'has', 'have', 'her', 'his', 'if', 'in', 'into', 'is', 'it', 'its', 'may', 'more', 'must', 'my', 'no', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'our', 'should', 'so', 'some', 'such', 'than', 'that', 'the', 'their', 'then', 'there', 'things', 'this', 'to', 'up', 'upon', 'was', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'would', 'your', 'random']\n"
     ]
    }
   ],
   "source": [
    "#What are some of the stop words we're looking at?\n",
    "features = list(authorship.columns)\n",
    "features.remove('Author')\n",
    "features.remove('Author_num')\n",
    "features.remove('BookID')\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a test and training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(authorship[features], authorship.Author_num.values, test_size=0.4, random_state=123)    \n",
    "x, y = authorship[features], authorship.Author_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976278869386\n",
      "[[135   2   0   0]\n",
      " [  1  96   0   1]\n",
      " [  0   0  20   0]\n",
      " [  0   1   0  81]]\n",
      "['Austen', 'London', 'Shakespeare', 'Milton']\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "etclf = ExtraTreesClassifier(n_estimators=20)\n",
    "etclf.fit(x_train, y_train)\n",
    "\n",
    "scores = cross_val_score(etclf, x, y)\n",
    "print scores.mean()\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print metrics.confusion_matrix(etclf.predict(x_test), y_test)\n",
    "print authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Determine how changing the parameters in the random forest model changes the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 estimators, the score is 0.797870403609\n",
      "With 2 estimators, the score is 0.771798552678\n",
      "With 3 estimators, the score is 0.881385933882\n",
      "With 4 estimators, the score is 0.903763367741\n",
      "With 5 estimators, the score is 0.919159062089\n",
      "With 6 estimators, the score is 0.931153676287\n",
      "With 7 estimators, the score is 0.93947051793\n",
      "With 8 estimators, the score is 0.937174300841\n",
      "With 9 estimators, the score is 0.957204857754\n",
      "With 10 estimators, the score is 0.939516789688\n",
      "With 11 estimators, the score is 0.956103474909\n",
      "With 12 estimators, the score is 0.960891043355\n",
      "With 13 estimators, the score is 0.964407696982\n",
      "With 14 estimators, the score is 0.958501738021\n",
      "With 15 estimators, the score is 0.972737158195\n",
      "With 16 estimators, the score is 0.966758962029\n",
      "With 17 estimators, the score is 0.973936017386\n",
      "With 18 estimators, the score is 0.971601760009\n",
      "With 19 estimators, the score is 0.972741364718\n"
     ]
    }
   ],
   "source": [
    "for estimator in range(1,20):\n",
    "    etclf = ExtraTreesClassifier(n_estimators=estimator)\n",
    "    etclf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(etclf, x, y)\n",
    "    print \"With \" + str(estimator) + \" estimators, the score is \" + str(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, the more estimators used the superior the performace of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Size of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a test size of 0.0 we get a score of 0.969182282704\n",
      "With a test size of 0.1 we get a score of 0.967996043084\n",
      "With a test size of 0.2 we get a score of 0.967953614696\n",
      "With a test size of 0.3 we get a score of 0.968008844231\n",
      "With a test size of 0.4 we get a score of 0.970381323472\n",
      "With a test size of 0.5 we get a score of 0.97867256282\n",
      "With a test size of 0.6 we get a score of 0.971520928181\n",
      "With a test size of 0.7 we get a score of 0.981045042061\n",
      "With a test size of 0.8 we get a score of 0.970360290854\n",
      "With a test size of 0.9 we get a score of 0.975118050483\n"
     ]
    }
   ],
   "source": [
    "for testSize in range(0,10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(authorship[features], authorship.Author_num.values, test_size=testSize/10.0, random_state=123)    \n",
    "    x, y = authorship[features], authorship.Author_num.values\n",
    "    etclf = ExtraTreesClassifier(n_estimators=20)\n",
    "    etclf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(etclf, x, y)\n",
    "    print \"With a test size of \" + str(testSize/10.0) + \" we get a score of \" + str(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the test size seems to make very little difference to the performance of the model.  A larger test set seems to marginally improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Size of random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random size of 0.0 we get a score of 0.973919009715\n",
      "With a random size of 10.0 we get a score of 0.971563538145\n",
      "With a random size of 20.0 we get a score of 0.977465109006\n",
      "With a random size of 30.0 we get a score of 0.978659761674\n",
      "With a random size of 40.0 we get a score of 0.980977192956\n",
      "With a random size of 50.0 we get a score of 0.973897795521\n",
      "With a random size of 60.0 we get a score of 0.968017438854\n",
      "With a random size of 70.0 we get a score of 0.965572540832\n",
      "With a random size of 80.0 we get a score of 0.97512646353\n",
      "With a random size of 90.0 we get a score of 0.971537935851\n"
     ]
    }
   ],
   "source": [
    "for randomSize in range(0,10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(authorship[features], authorship.Author_num.values, test_size=0.4, random_state=randomSize*10)    \n",
    "    x, y = authorship[features], authorship.Author_num.values\n",
    "    etclf = ExtraTreesClassifier(n_estimators=20)\n",
    "    etclf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(etclf, x, y)\n",
    "    print \"With a random size of \" + str(randomSize*10.0) + \" we get a score of \" + str(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the random state seems to make no difference to the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. See how using adaboost does on guess work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "ensemble.fit(x, y)\n",
    "ensemble.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost seems to do remarkably well when using the DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etclf = RandomForestClassifier(n_estimators=21)\n",
    "etclf.fit(x_train, y_train)\n",
    "scores = cross_val_score(etclf, x, y)\n",
    "\n",
    "ensemble = AdaBoostClassifier(base_estimator=RandomForestClassifier())\n",
    "ensemble.fit(x, y)\n",
    "ensemble.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also seems to work very well when using the random forest classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Try timing adaboost in comparison to randomforests to see how performance changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testAdaboost():\n",
    "    ensemble = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "    ensemble.fit(x, y)\n",
    "    ensemble.score(x, y)\n",
    "\n",
    "testAdaboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testRandomforest():\n",
    "    etclf = ExtraTreesClassifier(n_estimators=20)\n",
    "    etclf.fit(x_train, y_train)\n",
    "    scores = cross_val_score(etclf, x, y)\n",
    "\n",
    "testRandomforest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.5 ms per loop\n",
      "10 loops, best of 3: 87.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit testAdaboost()\n",
    "%timeit testRandomforest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting seems to have a clear speed advantage over randomforests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build a bagging algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "ensemble = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                             bootstrap=True,\n",
    "                             bootstrap_features=False,\n",
    "                             n_estimators=21)\n",
    "ensemble.fit(x, y)\n",
    "ensemble.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging algorithms also seem to do amazingly well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. How can ensemble methods be distributed across a cluster of servers? Can they be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is possible to distribute ensemble methods acorss a cluster of servers through techniques such as \"clustering\".  For example, a ‘two-stage’ course could be used whereby clustering first takes place in local sites and then in a global site. The process runs along the lines of:\n",
    "\n",
    "* Local clustering results transmitted to server site \n",
    "* These local results form an ensemble  \n",
    "* Use the ensemble to generate global clustering results \n",
    "\n",
    "A key consideration would be around how much sharing is required between servers and whether there are sharing restrictions.  It is apparently possible (albeit complex) to have privacy aware computation of a model when instances of the target data are distributed across different servers.\n",
    "\n",
    "Experimental results show that ensembles distributed across a cluster of servers can provide good classification\n",
    "accuracies while adhering to data/model sharing constraints.\n",
    "\n",
    "A rather complex paper explains more here - http://arxiv.org/pdf/1204.4521.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
